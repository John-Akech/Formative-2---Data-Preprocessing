{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1Rru4qWr3GSSGZcT/0VZg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/John-Akech/Formative-2---Data-Preprocessing/blob/master/Part_1_Data_Augmentation_on_CSV_Files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning & Handling Missing Values"
      ],
      "metadata": {
        "id": "vTfY58ERG-TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import uuid\n",
        "import datetime\n",
        "\n",
        "# Step 1: Load the Dataset\n",
        "try:\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv('/content/customer_transactions.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: The file 'customer_transactions.csv' was not found.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "AAJh0iuvFnd6"
      },
      "execution_count": 443,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic information\n",
        "print(\"\\nDataset Overview:\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X49ja_NjDe4N",
        "outputId": "867e1c66-f6a0-4bc8-9351-8c74118dafe7"
      },
      "execution_count": 444,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Overview:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 6 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   customer_id_legacy  150 non-null    int64  \n",
            " 1   transaction_id      150 non-null    int64  \n",
            " 2   purchase_amount     150 non-null    int64  \n",
            " 3   purchase_date       150 non-null    object \n",
            " 4   product_category    150 non-null    object \n",
            " 5   customer_rating     140 non-null    float64\n",
            "dtypes: float64(1), int64(3), object(2)\n",
            "memory usage: 7.2+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first few rows\n",
        "print(\"\\nFirst 5 Rows:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hvfi7_O3DhbO",
        "outputId": "b95bc237-22c8-4b18-e306-1c943cfc8b6a"
      },
      "execution_count": 445,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First 5 Rows:\n",
            "   customer_id_legacy  transaction_id  purchase_amount purchase_date  \\\n",
            "0                 151            1001              408    2024-01-01   \n",
            "1                 192            1002              332    2024-01-02   \n",
            "2                 114            1003              442    2024-01-03   \n",
            "3                 171            1004              256    2024-01-04   \n",
            "4                 160            1005               64    2024-01-05   \n",
            "\n",
            "  product_category  customer_rating  \n",
            "0           Sports              2.3  \n",
            "1      Electronics              4.2  \n",
            "2      Electronics              2.1  \n",
            "3         Clothing              2.8  \n",
            "4         Clothing              1.3  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Ensure Correct Data Types\n",
        "numerical_cols = ['purchase_amount', 'customer_rating']\n",
        "categorical_cols = ['product_category']"
      ],
      "metadata": {
        "id": "YXP8nOMuDkb4"
      },
      "execution_count": 446,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert purchase_date to datetime\n",
        "df['purchase_date'] = pd.to_datetime(df['purchase_date'], errors='coerce')"
      ],
      "metadata": {
        "id": "Vgz4vTS7Dmr3"
      },
      "execution_count": 447,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract year, month, and day from purchase_date\n",
        "df['year'] = df['purchase_date'].dt.year\n",
        "df['month'] = df['purchase_date'].dt.month\n",
        "df['day'] = df['purchase_date'].dt.day"
      ],
      "metadata": {
        "id": "hdy6YJbNDoxt"
      },
      "execution_count": 448,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the original purchase_date column\n",
        "df.drop(columns=['purchase_date'], inplace=True)"
      ],
      "metadata": {
        "id": "YhE9eZTjDq9P"
      },
      "execution_count": 449,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure numerical columns are numeric\n",
        "for col in numerical_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')"
      ],
      "metadata": {
        "id": "VeteqaaRDtTc"
      },
      "execution_count": 450,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure categorical columns are category type\n",
        "for col in categorical_cols:\n",
        "    df[col] = df[col].astype('category')"
      ],
      "metadata": {
        "id": "Ps_lr72yDvqM"
      },
      "execution_count": 451,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify updated data types\n",
        "print(\"\\nUpdated Data Types:\")\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-iJc-5TDxxO",
        "outputId": "f3e31e4c-3513-4f4f-af25-815abef9e8b3"
      },
      "execution_count": 452,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Updated Data Types:\n",
            "customer_id_legacy       int64\n",
            "transaction_id           int64\n",
            "purchase_amount          int64\n",
            "product_category      category\n",
            "customer_rating        float64\n",
            "year                     int32\n",
            "month                    int32\n",
            "day                      int32\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Handle Missing Values\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values Summary:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geB1BtcVDz0J",
        "outputId": "e0930b4b-5085-41ae-9b12-cdaca2a5e2d3"
      },
      "execution_count": 453,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing Values Summary:\n",
            "customer_id_legacy     0\n",
            "transaction_id         0\n",
            "purchase_amount        0\n",
            "product_category       0\n",
            "customer_rating       10\n",
            "year                   0\n",
            "month                  0\n",
            "day                    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute numerical columns using median\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "df[numerical_cols + ['year', 'month', 'day']] = imputer.fit_transform(df[numerical_cols + ['year', 'month', 'day']])"
      ],
      "metadata": {
        "id": "bEo2LllpD1wj"
      },
      "execution_count": 454,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute categorical columns using mode\n",
        "for col in categorical_cols:\n",
        "    mode_value = df[col].mode()[0]\n",
        "    df[col].fillna(mode_value, inplace=True)\n",
        "    print(f\"\\nFilled missing values in {col} with mode: {mode_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etGOoW0-D3mV",
        "outputId": "c86bbca7-b24e-4108-e29d-d2fa16a0dc09"
      },
      "execution_count": 455,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Filled missing values in product_category with mode: Sports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictive modeling for remaining missing values in customer_rating\n",
        "if df['customer_rating'].isnull().any():\n",
        "    X_train = df[df['customer_rating'].notnull()][['purchase_amount']]\n",
        "    y_train = df[df['customer_rating'].notnull()]['customer_rating']\n",
        "    X_missing = df[df['customer_rating'].isnull()][['purchase_amount']]\n",
        "\n",
        "    regressor = LinearRegression()\n",
        "    regressor.fit(X_train, y_train)\n",
        "    df.loc[df['customer_rating'].isnull(), 'customer_rating'] = regressor.predict(X_missing)"
      ],
      "metadata": {
        "id": "gfuN9y8dD5bC"
      },
      "execution_count": 456,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify missing values are handled\n",
        "print(\"\\nMissing Values After Imputation:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grqTwsdpD6_P",
        "outputId": "7e165182-ce12-4fe5-c8c5-b909835c0621"
      },
      "execution_count": 457,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing Values After Imputation:\n",
            "customer_id_legacy    0\n",
            "transaction_id        0\n",
            "purchase_amount       0\n",
            "product_category      0\n",
            "customer_rating       0\n",
            "year                  0\n",
            "month                 0\n",
            "day                   0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation Strategies"
      ],
      "metadata": {
        "id": "k0MvRMG-CpwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Apply Random Noise to Numerical Columns\n",
        "# Add random noise to purchase_amount\n",
        "noise_factor = 0.05  # Adjust noise factor for better augmentation\n",
        "original_std = df['purchase_amount'].std()\n",
        "df['purchase_amount'] += np.random.normal(0, noise_factor * original_std, df.shape[0])\n",
        "\n",
        "print(\"\\nRandom Noise Applied to purchase_amount:\")\n",
        "print(df[['purchase_amount']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yThNNeARLZHe",
        "outputId": "06e0a378-5965-4803-e5bb-6a6c86a8461f"
      },
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Noise Applied to purchase_amount:\n",
            "   purchase_amount\n",
            "0       410.440595\n",
            "1       323.515841\n",
            "2       444.550128\n",
            "3       261.623278\n",
            "4        60.853957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Transform Skewed Features\n",
        "# Check skewness\n",
        "skewness = df['purchase_amount'].skew()\n",
        "print(f\"\\nSkewness of purchase_amount: {skewness}\")\n",
        "\n",
        "# Apply log transformation if skewed\n",
        "if skewness > 1:\n",
        "    df['purchase_amount'] = np.log1p(df['purchase_amount'])\n",
        "    print(\"\\nLog Transformation Applied to purchase_amount.\")\n",
        "\n",
        "print(\"\\nTransformed purchase_amount:\")\n",
        "print(df[['purchase_amount']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQ3E478OEAVA",
        "outputId": "c495e4eb-2a36-42f4-e01e-857923e395cc"
      },
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Skewness of purchase_amount: 0.040473043333057894\n",
            "\n",
            "Transformed purchase_amount:\n",
            "   purchase_amount\n",
            "0       410.440595\n",
            "1       323.515841\n",
            "2       444.550128\n",
            "3       261.623278\n",
            "4        60.853957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Generate Synthetic Data (Choose One Approach)\n",
        "\n",
        "# Approach 1: Discretize Target Variable and Use SMOTE\n",
        "def augment_with_smote(df):\n",
        "    # Encode categorical variables\n",
        "    X = df.drop(columns=['customer_id_legacy', 'transaction_id', 'customer_rating'])\n",
        "    y = df['customer_rating']\n",
        "\n",
        "    # One-hot encode categorical features\n",
        "    encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
        "    X_encoded = encoder.fit_transform(X[categorical_cols])\n",
        "    X_encoded = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "    X_final = pd.concat([X.drop(columns=categorical_cols), X_encoded], axis=1)\n",
        "\n",
        "    # Discretize the continuous target into bins\n",
        "    discretizer = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
        "    y_discrete = discretizer.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "    # Apply SMOTE to the discretized target\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_resampled, y_resampled = smote.fit_resample(X_final, y_discrete)\n",
        "\n",
        "    # Decode the discretized target back to the original scale\n",
        "    y_resampled_continuous = discretizer.inverse_transform(y_resampled.reshape(-1, 1)).ravel()\n",
        "\n",
        "    # Combine resampled data into a DataFrame\n",
        "    synthetic_data = pd.DataFrame(X_resampled, columns=X_final.columns)\n",
        "    synthetic_data['customer_rating'] = y_resampled_continuous\n",
        "\n",
        "    # Decode one-hot-encoded features back to original format\n",
        "    def decode_one_hot(encoded_df, original_df):\n",
        "        decoded_df = pd.DataFrame(index=encoded_df.index)\n",
        "        for col in categorical_cols:\n",
        "            one_hot_cols = [c for c in encoded_df.columns if c.startswith(col)]\n",
        "            decoded_df[col] = encoded_df[one_hot_cols].idxmax(axis=1).str.replace(f\"{col}_\", \"\")\n",
        "        return decoded_df\n",
        "\n",
        "    decoded_categoricals = decode_one_hot(synthetic_data, X)\n",
        "    synthetic_data = pd.concat([synthetic_data.drop(columns=[c for c in synthetic_data.columns if any(cat in c for cat in categorical_cols)]), decoded_categoricals], axis=1)\n",
        "\n",
        "    # Generate synthetic IDs\n",
        "    synthetic_data['customer_id_legacy'] = [uuid.uuid4().int % 10**9 for _ in range(synthetic_data.shape[0])]\n",
        "    synthetic_data['transaction_id'] = range(df['transaction_id'].max() + 1, df['transaction_id'].max() + 1 + synthetic_data.shape[0])\n",
        "\n",
        "    return synthetic_data"
      ],
      "metadata": {
        "id": "LS2UCLffEASY"
      },
      "execution_count": 460,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Approach 2: Interpolation for Continuous Target\n",
        "def augment_with_interpolation(df):\n",
        "    # Function to generate synthetic samples via interpolation\n",
        "    def interpolate_data(X, y, n_samples):\n",
        "        synthetic_X = []\n",
        "        synthetic_y = []\n",
        "\n",
        "        for _ in range(n_samples):\n",
        "            # Randomly select two samples\n",
        "            idx1, idx2 = np.random.choice(len(X), size=2, replace=False)\n",
        "            alpha = np.random.uniform(0, 1)  # Interpolation factor\n",
        "\n",
        "            # Interpolate features and target\n",
        "            synthetic_X.append(alpha * X.iloc[idx1] + (1 - alpha) * X.iloc[idx2])\n",
        "            synthetic_y.append(alpha * y.iloc[idx1] + (1 - alpha) * y.iloc[idx2])\n",
        "\n",
        "        synthetic_X = pd.DataFrame(synthetic_X, columns=X.columns)\n",
        "        synthetic_y = pd.Series(synthetic_y, name=y.name)\n",
        "        return synthetic_X, synthetic_y\n",
        "\n",
        "    # Prepare data for augmentation\n",
        "    X = df.drop(columns=['customer_id_legacy', 'transaction_id', 'customer_rating'])\n",
        "    y = df['customer_rating']\n",
        "\n",
        "    # Generate synthetic data\n",
        "    n_synthetic_samples = len(df)  # Generate as many synthetic samples as the original dataset\n",
        "    synthetic_X, synthetic_y = interpolate_data(X, y, n_synthetic_samples)\n",
        "\n",
        "    # Combine synthetic data into a DataFrame\n",
        "    synthetic_data = pd.concat([synthetic_X, synthetic_y], axis=1)\n",
        "    synthetic_data.columns = X.columns.tolist() + ['customer_rating']\n",
        "\n",
        "    # Generate synthetic IDs\n",
        "    synthetic_data['customer_id_legacy'] = [uuid.uuid4().int % 10**9 for _ in range(synthetic_data.shape[0])]\n",
        "    synthetic_data['transaction_id'] = range(df['transaction_id'].max() + 1, df['transaction_id'].max() + 1 + synthetic_data.shape[0])\n",
        "\n",
        "    return synthetic_data"
      ],
      "metadata": {
        "id": "9WKy6a84EAQL"
      },
      "execution_count": 461,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose an augmentation approach\n",
        "augmentation_method = \"smote\"  # Change to \"interpolation\" if needed\n",
        "\n",
        "if augmentation_method == \"smote\":\n",
        "    synthetic_data = augment_with_smote(df)\n",
        "elif augmentation_method == \"interpolation\":\n",
        "    synthetic_data = augment_with_interpolation(df)\n",
        "\n",
        "# Concatenate synthetic data with the original dataset\n",
        "df_augmented = pd.concat([df, synthetic_data], axis=0).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nSynthetic Data Generated:\")\n",
        "print(synthetic_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iWsA34JD_98",
        "outputId": "0b9bc85d-aad2-4b47-e45a-e4cfdf72a0ad"
      },
      "execution_count": 462,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Synthetic Data Generated:\n",
            "   purchase_amount    year  month  day  customer_rating product_category  \\\n",
            "0       410.440595  2024.0    1.0  1.0         1.666667           Sports   \n",
            "1       323.515841  2024.0    1.0  2.0         4.333333      Electronics   \n",
            "2       444.550128  2024.0    1.0  3.0         1.666667      Electronics   \n",
            "3       261.623278  2024.0    1.0  4.0         3.000000         Clothing   \n",
            "4        60.853957  2024.0    1.0  5.0         1.666667         Clothing   \n",
            "\n",
            "   customer_id_legacy  transaction_id  \n",
            "0            89990907            1151  \n",
            "1           874511730            1152  \n",
            "2           594087804            1153  \n",
            "3           210559944            1154  \n",
            "4           366967634            1155  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export the Augmented Data"
      ],
      "metadata": {
        "id": "FL45miP1C6Fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the Augmented Dataset\n",
        "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "output_file = f'customer_transactions_augmented_{timestamp}.csv'\n",
        "df_augmented.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"\\nAugmented Dataset Saved Successfully as '{output_file}'!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhruE4RiC6_8",
        "outputId": "2d9c3d0a-8171-41d6-c02f-6a70c5aaea75"
      },
      "execution_count": 463,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Augmented Dataset Saved Successfully as 'customer_transactions_augmented_20250316_174840.csv'!\n"
          ]
        }
      ]
    }
  ]
}